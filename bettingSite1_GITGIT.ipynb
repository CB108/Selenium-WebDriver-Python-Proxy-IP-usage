{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries & DEFINE FUNCTIONS \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import random\n",
    "\n",
    "#Web scraping imports \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import urllib.request\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException as TOE\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.common.proxy import Proxy,ProxyType\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common import exceptions\n",
    "from selenium.common.exceptions import WebDriverException as WDE\n",
    "\n",
    "\n",
    "\n",
    "# For Viz\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other \n",
    "\n",
    "from itertools import product\n",
    "import collections\n",
    "from collections import Counter\n",
    "from itertools import permutations\n",
    "from urllib.error import HTTPError, URLError\n",
    "    \n",
    "    \n",
    "    \n",
    "# --------- GET_PROXIES() & CHECK_PROXIES() were adapted from towardsdatascience.com \n",
    "    \n",
    "    \n",
    "def get_proxies():\n",
    "\n",
    "    proxy_web_site = 'not_included'\n",
    "    response = requests.get(proxy_web_site)\n",
    "    page_html = response.text\n",
    "    page_soup = bs(page_html, \"html.parser\")\n",
    "    container = page_soup.find_all(\"div\", {\"class\": \"table-responsive\"})[0]\n",
    "    multi_by = [8*i for i in range(299)]\n",
    "    proxies = set()\n",
    "    \n",
    "    for x in multi_by:\n",
    "        country = container.find_all(\"td\")[x+2].text \n",
    "        ip = container.find_all(\"td\")[x].text\n",
    "        port = container.find_all(\"td\")[x+1].text\n",
    "        if country == 'US':\n",
    "            proxy = ip + ':' + port\n",
    "            proxies.add(proxy)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    return proxies \n",
    "\n",
    "def check_proxies():\n",
    "    \n",
    "    working_proxies = set()\n",
    "    proxies = get_proxies()            \n",
    "    test_url = 'not_included'    \n",
    "    for i in proxies:\n",
    "        try:\n",
    "            response = requests.get(test_url, proxies={\"https\": i}, timeout = 10)\n",
    "            working_proxies.add(i)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return working_proxies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bettingSite1():\n",
    "   \n",
    "\n",
    "    # Get proxies, print proxies, test proxies\n",
    "    prox_listIP = check_proxies()\n",
    "    prox_listIP = list(prox_listIP)\n",
    "    prox_listIP.insert(0, 'most_reliable_proxy')\n",
    "    print(prox_listIP)\n",
    "    \n",
    "    \n",
    "    # Variable for either starting or stopping the program\n",
    "    red_green = 0\n",
    "    while red_green == 0:     \n",
    "        \n",
    "        # if there are no more ips then it quits the program\n",
    "        # Because we are popping [0] below if it doesnt work it automatically cycles the next ip into the [0] spot\n",
    "        try:\n",
    "            the_ip = prox_listIP[0]\n",
    "            pass\n",
    "        except:\n",
    "            print(\"no proxies passed\")\n",
    "            quit()\n",
    "            browser.quit()\n",
    "\n",
    "        # Open Chrome in Stealth\n",
    "        capabilities = webdriver.DesiredCapabilities.CHROME\n",
    "        prox = Proxy()\n",
    "        prox.proxy_type = ProxyType.MANUAL\n",
    "        prox.autodetect = False\n",
    "        prox.http_proxy = the_ip\n",
    "        prox.ssl_proxy = the_ip\n",
    "        prox.ftp_proxy = the_ip\n",
    "        prox.add_to_capabilities(capabilities)\n",
    "\n",
    "        option = webdriver.ChromeOptions()\n",
    "        #For ChromeDriver version 79.0.3945.16 or over to go stealth\n",
    "        # IF FOR SOME REASON THIS IS HERE TWICE option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        #For working from a proxie\n",
    "        option.add_argument('--proxy-server=%s' % the_ip)\n",
    "        # THE THREE BELOW OR FOR AVOIDING CLOUDFLARE DETECTION\n",
    "        option.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        option.add_experimental_option('useAutomationExtension', False)\n",
    "        option.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "\n",
    "        path_to_driver = '/Users/blank/Desktop/chromedriver'\n",
    "        browser = webdriver.Chrome(executable_path = path_to_driver, options=option, desired_capabilities= capabilities)\n",
    "\n",
    "        # STEALTH \n",
    "\n",
    "        # Remove navigator.webdriver Flag using JavaScript\n",
    "        browser.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "\n",
    "        # browser.get(\"https://httpbin.org/ip\")\n",
    "        url = \"sports_betting_site1\"\n",
    "        browser.get(url)\n",
    "\n",
    "        # Checking to see if it actually loaded and if should continue with this IP\n",
    "        try:\n",
    "            WebDriverWait(browser,60).until(EC.presence_of_element_located((By.XPATH, '/html/body/*')))\n",
    "            print(\"passed xpath test\")\n",
    "        except WDE:\n",
    "            pass\n",
    "        except:\n",
    "            browser.quit()\n",
    "            print(\"nothing loaded after 45 seconds\")\n",
    "            quit()\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_id('t')\n",
    "            time.sleep(5)\n",
    "            if browser.find_element_by_id('t'):\n",
    "                prox_listIP.pop(0)\n",
    "                print('popped from list at found t')\n",
    "                browser.quit()\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_id('cf-wrapper')\n",
    "            prox_listIP.pop(0)\n",
    "            print('popped from list at found cf-wrapper')\n",
    "            browser.quit()\n",
    "        except:\n",
    "            red_green += 1\n",
    "                                        \n",
    "\n",
    "    #Just wait a little\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Scroll to bottom of the page\n",
    "    browser.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "\n",
    "    # Make sure page loads if not try refresh three time unless there is a clear bad-proxy error\n",
    "    main_page_load_test = 0\n",
    "    refresh_count = 0\n",
    "\n",
    "    while main_page_load_test != 1:\n",
    "        # Wait for it to load the \n",
    "        try:\n",
    "            main_page_load_test = 0\n",
    "            WebDriverWait(browser,25).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button[class*=\"add-to-betslip\"]')))\n",
    "            WebDriverWait(browser,5).until(EC.element_to_be_clickable((By.LINK_TEXT, 'Promotions')))\n",
    "            main_page_load_test += 1\n",
    "        except:\n",
    "            browser.refresh()\n",
    "            refresh_count += 1\n",
    "            if refresh_count > 3:\n",
    "                browser.quit()\n",
    "\n",
    "    #change odds format \n",
    "    odds_drop_down = browser.find_element_by_css_selector('span[id=\"react-select-3--value-item\"]')\n",
    "    odds_drop_down.click()\n",
    "    time.sleep(2)\n",
    "    decimal_link = browser.find_element_by_css_selector('div[id=\"react-select-3--option-0\"]')\n",
    "    decimal_link.click()\n",
    "\n",
    "\n",
    "    # CREATING LINKS AND LIST\n",
    "\n",
    "\n",
    "    # Creating master list for BetFred\n",
    "    sportsBettingSite1_masterList = []\n",
    "    # For counting sports\n",
    "    \n",
    "    \n",
    "    # --- LOOP STARTS HERE \n",
    "    \n",
    "    \n",
    "    \n",
    "    # START LOOPING HERE \n",
    "    for sport in range(8):\n",
    "    \n",
    "       \n",
    "        # Make sure things did not go stale and that connection is still active \n",
    "        browser.refresh()\n",
    "        time.sleep(5)\n",
    "            \n",
    "        # Making sure its all a go and proceeding\n",
    "        browser.refresh()\n",
    "        try:\n",
    "            WebDriverWait(browser,45).until(EC.element_to_be_clickable((By.LINK_TEXT, 'Promotions')))\n",
    "            time.sleep(10)\n",
    "        except:\n",
    "            print(\"Promotions\")\n",
    "            browser.quit()\n",
    "            quit()\n",
    "\n",
    "        time.sleep(2)\n",
    "        # Scroll to bottom of the page \n",
    "        browser.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        # SCROLL THE PAGE TO THE TENNIS LINK\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView();\", browser.find_element_by_link_text('Tennis'))\n",
    "        # Wait for it to load the \n",
    "        try:\n",
    "            WebDriverWait(browser,45).until(EC.element_to_be_clickable((By.LINK_TEXT, 'Tennis')))\n",
    "        except:\n",
    "            browser.quit()\n",
    "        # SCROLL THE PAGE TO THE BASEBALL LINK - this makes it all visible\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView();\", browser.find_element_by_link_text('Baseball'))\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Hockey Link \n",
    "        hockey_link = browser.find_element_by_link_text('Ice Hockey')\n",
    "        # Soccer Link \n",
    "        soccer_link = browser.find_element_by_link_text(\"Soccer\")\n",
    "        # UFC/MMA Link \n",
    "        ufc_mma_link = browser.find_element_by_link_text(\"Mixed Martial Arts\")\n",
    "        # Tennis Link \n",
    "        tennis_link = browser.find_element_by_link_text(\"Tennis\")\n",
    "        # Boxing Link \n",
    "        boxing_link = browser.find_element_by_link_text(\"Boxing\")\n",
    "        # Baseball Link\n",
    "        baseball_link = browser.find_element_by_link_text(\"Baseball\")\n",
    "        # Basketball Link\n",
    "        basketball_link = browser.find_element_by_link_text(\"Basketball\")\n",
    "        # Table Tennis Link \n",
    "        table_tennis_link = browser.find_element_by_link_text(\"Table Tennis\")\n",
    "\n",
    "        # Create sports_link_list for format1 sports\n",
    "        sports_links = [hockey_link,ufc_mma_link,tennis_link,boxing_link,baseball_link,table_tennis_link,basketball_link,soccer_link]\n",
    "\n",
    "\n",
    "        # Clicking on the link for each new sport\n",
    "        try:\n",
    "            sports_links[sport].click()\n",
    "        except exceptions.StaleElementReferenceException as stale:\n",
    "            print(stale)\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(browser,45).until(EC.element_to_be_clickable((By.LINK_TEXT, 'MLB')))\n",
    "        except:\n",
    "            browser.quit()\n",
    "\n",
    "\n",
    "        time.sleep(3)\n",
    "        browser.execute_script(\"window.scrollBy(0,document.body.scrollHeight)\")\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "        # check if there are any 'load more' links \n",
    "        try:\n",
    "            load_more = browser.find_elements_by_link_text(\"Load More...\")\n",
    "            for x in load_more:\n",
    "                x.click()\n",
    "                time.sleep(2) \n",
    "        except:\n",
    "            print(f\"did not find load more button for: {sports_links[sport]}\")\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Finding info\n",
    "        all_events = browser.find_elements_by_css_selector('div[class=\"event-list__item-link\"]')\n",
    "        for x in all_events:\n",
    "            try:\n",
    "                location = browser.current_url\n",
    "                event_html = x.get_attribute('outerHTML')\n",
    "                event_soup = bs(event_html, 'html.parser')\n",
    "                spans = event_soup.find_all('span')\n",
    "                if sport == 6: # Basketball\n",
    "                    side_1_name = spans[14]\n",
    "                    side_2_name = spans[19]\n",
    "                    side_1_odds = spans[16] \n",
    "                    side_2_odds = spans[21]\n",
    "                elif sport == 7: # Soccer \n",
    "                    side_1_name = spans[2]\n",
    "                    side_2_name = spans[12]\n",
    "                    side_1_odds = spans[4] \n",
    "                    side_2_odds = spans[14]\n",
    "                else: # The Rest \n",
    "                    side_1_odds = spans[4] \n",
    "                    side_2_odds = spans[9]\n",
    "                    side_1_name = spans[2]\n",
    "                    side_2_name = spans[7]\n",
    "                sport_name = browser.find_elements_by_css_selector('a[role=\"menuitem\"]')[1]\n",
    "                event_name = side_1_name.text + ' vs ' + side_2_name.text\n",
    "                event_date_time = x.find_element_by_css_selector('div[class$=\"event-market-footer\"]')\n",
    "                #create list and print for test \n",
    "                each_event_list = [url,location,sport_name.text,event_name,event_date_time.text,side_1_name.text,side_1_odds.text,side_2_name.text,side_2_odds.text]\n",
    "                sportsBettingSite1_masterList.append(each_event_list)\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    return sportsBettingSite1_masterList\n",
    "    \n",
    "    # Ends and Quits Browser\n",
    "    print(\"completed bet_fred\")\n",
    "    browser.quit()\n",
    "\n",
    "# --- RUNS HERE    \n",
    "\n",
    "sportsBettingSite1_List = bettingSite1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
